{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educated-response",
   "metadata": {},
   "source": [
    "### Tree mortality prediction based on growth patterns\n",
    "\n",
    "data: [HF213](https://harvardforest1.fas.harvard.edu/exist/apps/datasets/showData.html?id=HF213)\n",
    "\n",
    "Use classification algorithms to predict A(live) or D(ead) labels in __mortality13__ and __mortality14__ columns using these features:  \n",
    " - spp: USDA Plants database species code  \n",
    " - dbh09: diameter at Breast Height (1.4m) in year 2009 (unit: centimeter / missing value: NA)  \n",
    " - dbh11: diameter at Breast Height (1.4m) in year 2011 (unit: centimeter / missing value: NA)  \n",
    " - dbh12: diameter at Breast Height (1.4m) in year 2012 (unit: centimeter / missing value: NA)  \n",
    " - dbh13: diameter at Breast Height (1.4m) in year 2013 (unit: centimeter / missing value: NA)  \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "##### Tree mortality prediction based on growth patterns using Machine Learning\n",
    "Forests are critically important for biodiversity and provide important health and economic benefits. Forests' response to climate change is however not very well understood. This project addresses the importance of tree growth rate for understanding and predicting tree mortality rates. It is hypothesized that trees' growth patterns across multiple species may have subtle changes when trees are under stress and that growth changes over time can be used as an early predictor for tree mortality. For tree growth we use Diameter at Breast Height (dbh) measurements collected 4, 2, 1 and 0 (during the year of tree death) years previous to tree death. For modelling, we trained data driven machine learning models for mortality prediction using data classification. Our results show that simple growth measurements can be used to predict mortality with a reasonable performance (>.65 Area under ROC curve on test data ).  Further studies should use larger datasets to see if the modelsâ€™ accuracy can be increased. Mortality prediction models can further be used to understand which species are most likely to exhibit change in growth patterns under stress, as well as understand how early the changes appear before death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pathlib, shutil, platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    StratifiedShuffleSplit,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIMUM_COUNT = 10\n",
    "TRAIN_DATA = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/opt/conda/bin/conda install -c anaconda seaborn pandas scikit-learn -y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# !ls -la ./../data/hrvardf/HF213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileName='hf213-01-hf-inventory.csv'\n",
    "dataPathFull= pathlib.Path('./../data/harvardf/HF213') / dataFileName\n",
    "myData = pd.read_csv(str(dataPathFull)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData.shape\n",
    "myData.head(2)\n",
    "myData.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData.info()\n",
    "myData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myData.dropna()\n",
    "# myData.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic descriptive statistics for numeric columns:\n",
    "myData.describe()\n",
    "myData.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myData.groupby('spp').size()\n",
    "myCols = ['spp', 'mortality13', 'dmg13']\n",
    "myData[myCols[0]].value_counts(dropna=False) \n",
    "myData[myCols[1]].value_counts(dropna=False)\n",
    "myData[myCols[2]].value_counts(dropna=False)\n",
    "myData.pivot_table(index = [myCols[0]]\n",
    "                   , columns = myCols[1]\n",
    "                   , values =  myCols[2]\n",
    "                   , aggfunc=np.sum, fill_value=0)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x= myData['spp'],label=\"spp Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData['spp'].value_counts(dropna=False) \n",
    "removeSPP = myData['spp'].value_counts(dropna=False).loc[lambda x : x<MINIMUM_COUNT].index.tolist()\n",
    "removeSPP\n",
    "\n",
    "# filteredData = myData.replace(dict.fromkeys(removeSPP, 'TooFew'))\n",
    "# filteredData['spp'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumn_01=['spp', 'dbh09', 'dbh11', 'dbh12']\n",
    "# featureColumn_01=[ 'dbh09', 'dbh11', 'dbh12']\n",
    "labelColumn_01 = 'mortality13'\n",
    "featureColumn_02=['spp', 'dbh09', 'dbh11', 'dbh12', 'dbh13']\n",
    "# featureColumn_02=['dbh09', 'dbh11', 'dbh12', 'dbh13']\n",
    "labelColumn_02 = 'mortality14' \n",
    "\n",
    "labelColumn = labelColumn_02\n",
    "featureColumn = featureColumn_02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(featureColumn+[labelColumn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = myData\n",
    "filteredDataML = filteredData[sorted(set(featureColumn+[labelColumn]))]\n",
    "\n",
    "filteredDataML.shape\n",
    "filteredDataML.head()\n",
    "filteredDataML[labelColumn].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDataML[labelColumn].value_counts(dropna=False)\n",
    "\n",
    "filteredDataML = filteredDataML[filteredDataML[labelColumn].isin(['D', 'A'])]\n",
    "filteredDataML.shape\n",
    "filteredDataML.head()\n",
    "\n",
    "\n",
    "filteredDataML[labelColumn].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html#sphx-glr-auto-examples-ensemble-plot-stack-predictors-py\n",
    "\n",
    "catCols = filteredDataML.columns[filteredDataML.dtypes == 'O']\n",
    "numCols = filteredDataML.columns[filteredDataML.dtypes == 'float64']\n",
    "catCols\n",
    "numCols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratifySplit = StratifiedShuffleSplit(n_splits=1, train_size=TRAIN_DATA, random_state=1)\n",
    "\n",
    "trainIdx, tstIdx = next(stratifySplit.split(filteredDataML, filteredDataML[labelColumn]))\n",
    "# print(\"\\n Train:\", sorted(trainIdx))\n",
    "len(trainIdx)\n",
    "len(tstIdx)\n",
    "\n",
    "filteredDataML.loc[filteredDataML.index.intersection(filteredDataML.index[trainIdx])].shape\n",
    "filteredDataML[filteredDataML.index.isin(filteredDataML.index[trainIdx])].shape\n",
    "aa=filteredDataML.loc[filteredDataML.index.intersection(filteredDataML.index[tstIdx])]\n",
    "aa.shape\n",
    "stratifySplit = StratifiedShuffleSplit(n_splits=1, train_size=TRAIN_DATA, test_size=1-TRAIN_DATA, random_state=1)\n",
    "testIdx, validationIdx = next(stratifySplit.split(aa,  aa[labelColumn]))\n",
    "\n",
    "len(testIdx)\n",
    "len(validationIdx)\n",
    "filteredDataML.shape\n",
    "\n",
    "# testIdx=tstIdx[testIdx]\n",
    "# validationIdx=tstIdx[validationIdx]\n",
    "\n",
    "# print(\"\\n Test:\", sorted(testIdx))\n",
    "# print(\"\\nValidation:\", sorted(validationIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData=filteredDataML.loc[filteredDataML.index.intersection(filteredDataML.index[trainIdx]),:]\n",
    "testData=aa.loc[aa.index.intersection(aa.index[testIdx]),:]\n",
    "validationData = aa.loc[aa.index.intersection(aa.index[validationIdx]),:]\n",
    "\n",
    "filteredDataML[labelColumn].value_counts(dropna=False)\n",
    "trainData[labelColumn].value_counts(dropna=False) \n",
    "testData[labelColumn].value_counts(dropna=False) \n",
    "validationData[labelColumn].value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinalEncoder = OrdinalEncoder()\n",
    "ordinalEncoder.fit(filteredDataML[catCols])\n",
    "ordinalEncoder.categories_\n",
    "\n",
    "trainData[catCols] = ordinalEncoder.transform(trainData[catCols])\n",
    "testData[catCols] = ordinalEncoder.transform(testData[catCols])\n",
    "validationData[catCols] = ordinalEncoder.transform(validationData[catCols])\n",
    "\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(trainData[featureColumn])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[featureColumn] = imputer.transform(trainData[featureColumn])\n",
    "testData[featureColumn] = imputer.transform(testData[featureColumn])\n",
    "validationData[featureColumn] = imputer.transform(validationData[featureColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = svm.SVC(kernel='rbf', random_state=0, gamma=.1, C=100, probability=True)\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=50)\n",
    "RF_model = RandomForestClassifier(n_estimators=10, class_weight=dict({0:10000., 1:10.}))\n",
    "\n",
    "\n",
    "SVC_model.fit(trainData[featureColumn], trainData[labelColumn])\n",
    "KNN_model.fit(trainData[featureColumn], trainData[labelColumn])\n",
    "RF_model.fit(trainData[featureColumn], trainData[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_prediction = SVC_model.predict(testData[featureColumn])\n",
    "KNN_prediction = KNN_model.predict(testData[featureColumn])\n",
    "RF_prediction  = RF_model.predict(testData[featureColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(SVC_prediction, testData[labelColumn])\n",
    "accuracy_score(KNN_prediction, testData[labelColumn])\n",
    "accuracy_score(RF_prediction, testData[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(SVC_prediction, testData[labelColumn])\n",
    "confusion_matrix(KNN_prediction, testData[labelColumn])\n",
    "confusion_matrix(RF_prediction, testData[labelColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(SVC_prediction,  testData[labelColumn]))\n",
    "print(classification_report(KNN_prediction,  testData[labelColumn]))\n",
    "print(classification_report(RF_prediction,  testData[labelColumn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-approach",
   "metadata": {},
   "source": [
    "#### SVM SVC ROC curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_prediction_probs = SVC_model.predict_proba(testData[featureColumn])\n",
    "fpr, tpr, thresholds = roc_curve(testData[labelColumn], SVC_prediction_probs[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "import pylab as pl\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Receiver operating characteristic')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model_linear = svm.SVC(kernel=\"linear\", C=100)\n",
    "\n",
    "# rfe = RFE(estimator=SVC_model_linear, n_features_to_select=1, step=1, verbose=2)\n",
    "# rfe.fit(trainData[featureColumn], trainData[labelColumn])\n",
    "# ranking = rfe.ranking_\n",
    "\n",
    "# # # Plot  ranking\n",
    "# # plt.matshow(ranking, cmap=plt.cm.Blues)\n",
    "# # plt.colorbar()\n",
    "# # plt.title(\"feature importance RFE\")\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_features_to_select = 1  # Minimum number of features to consider\n",
    "# rfecv = RFECV(estimator=SVC_model_linear, step=1, cv=StratifiedKFold(2),\n",
    "#               scoring='accuracy',\n",
    "#               min_features_to_select=min_features_to_select)\n",
    "# rfecv.fit(trainData[featureColumn], trainData[labelColumn])\n",
    "\n",
    "# print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# # Plot number of features VS. cross-validation scores\n",
    "# plt.figure()\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "# plt.plot(range(min_features_to_select,\n",
    "#                len(rfecv.grid_scores_) + min_features_to_select),\n",
    "#          rfecv.grid_scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
